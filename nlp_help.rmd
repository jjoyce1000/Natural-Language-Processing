---
title: "Natural Language Processing - Text Prediction"
author: "John Joyce"
date: "March 26, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###**Introduction**  
Around the world, people are spending an increasing amount of time on their mobile devices for email, social networking, banking and a whole range of other activities. But typing on mobile devices can be cumbersome.   SwiftKey, the corporate partner of the Johns Hopkins Data Science capstone, builds a smart keyboard that makes it easier for people to type on their mobile devices. One cornerstone of their smart keyboard is predictive text models.  

This data science capstone project analyzes a large corpus of text documents for twitter, blogs, and news to discover the structure in the data to build a predictive text product.

###**Application Usage**  
This basic Shiny product emulates a predictive text algorithm that evaluates the free text input of the user in real time.  
The application allows the user to specify the 'word history count' to be used in the prediction algorithm.

- Input:  
  Text within text box and 'Number of Words to Evaluate' via the slider bar (Ranges from 1-5 with default of 5).  
    
- Output:  
  Plot of the Top 10 word sequences based upon the user input and probability of 'next word' witin the sequence.  
  A text box showing the words that are currently getting evaluated based on the user input.  
  A text box showing the 'predicted next word'.  
    
###**Data Analysis**

Source of data training sets:  

- <a href="https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip">SwiftKey US Locale Data</a>  
- <a href="https://www.cs.cmu.edu/~biglou/resources/bad-words.txt">Profanity Data Set</a>  

The training data set is sampled at 20% and converted to sentences to better estimate word prediction that accounts for ngrams within sentence boundaries. The sampled data set is then loaded into a corpus for efficient manipulation of text data. Within the corpus, several procedures are used to clean and filter the data, including the conversion of non-ASCII text to ASCII text and conversion of all characters to lowercase. It also incluces the removal of profanity, punctuation, numbers, and whitespace.

There are several R scripts that are used to perform this analysis:  

- [nlp_load_files.R](https://github.com/jjoyce1000/Natural-Language-Processing/blob/master/nlp_load_files.R):  
  This script loads the files for the Natural Language Processing - Text Prediction project.  
        
- [nlp_setup.R](https://github.com/jjoyce1000/Natural-Language-Processing/blob/master/nlp_setup.R):  
  This script installs packages and loads libraries needed to support the Natural Language Processing - Text Prediction project.  
        
- [nlp_read.R](https://github.com/jjoyce1000/Natural-Language-Processing/blob/master/nlp_read.R):  
  This script loads the US data set used for the Natural Language Processing - Text Prediction project.  
  This script also reads the profanity.csv file used for cleaning the corpus documents.  
  This script also generates initial files statistics for the data sets.  

- [nlp_clean.R](https://github.com/jjoyce1000/Natural-Language-Processing/blob/master/nlp_clean.R):  
  This script defines functions to clean and manipulate corpus data for the Natural Language Processing - Text Prediction project.  

- [global.R](hhttps://github.com/jjoyce1000/Natural-Language-Processing/blob/master/global.R):  
  This script serves as the global.R file for the Natural Language Processing - Text Prediction Shiny Application. 
  
- [ui.R](https://github.com/jjoyce1000/Natural-Language-Processing/blob/master/ui.R):  
  This script defines the ui.R functionality for the Natural Language Processing - Text Prediction Shiny Application.  
  This script builds a Shiny dashboard with text and slider input. It also creates the framework for the output boxes.

- [server.R](https://github.com/jjoyce1000/Natural-Language-Processing/blob/master/server.R):  
  This script defines the server.R functionality for the Natural Language Processing - Text Prediction Shiny Application.  
  This script provides the output for the application based upon the user text box and slider input.

###**Prediction Algorithm / Methodology**

- Once the cleaned corpus data is compiled, the RWeka package is used to tokenize the data into ngrams
  of length 1 thru 6. 
- The ngrams are compiled to serve as the 'dictionary' for this application in the form of .rds files.
- When the Shiny application is initialized, the 'dictionary' files are loaded and referenced as the 
  user enters the text and 'number of words to evaluate' input.
- The algorithm uses a backoff algorithm that starts with an attempt to match the longest word sequence
  from the user input.  If no match is found, then next longest sequence is evaluated.

###**References**

- <a href="https://jjoyce1000.shinyapps.io/NLP_Text_Prediction/">NLP Text Prediction Shiny Application</a> 
- <a href="https://github.com/jjoyce1000/Natural-Language-Processing">GitHub Repository</a> 
- <a href="http://rpubs.com/jjoyce1000/NLP_Presentation">NLP Text Prediction Presentation</a> 
- <a href="https://www.coursera.org/specializations/jhu-data-science">Johns Hopkins Data Science</a> 